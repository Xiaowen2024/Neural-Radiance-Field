{"cells":[{"cell_type":"markdown","metadata":{"id":"MolbqoBw7Ur0"},"source":["Part2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:27:51.075915Z","iopub.status.busy":"2023-11-17T00:27:51.074986Z","iopub.status.idle":"2023-11-17T00:27:51.291813Z","shell.execute_reply":"2023-11-17T00:27:51.290769Z","shell.execute_reply.started":"2023-11-17T00:27:51.075876Z"},"id":"Zata9KVq7WPp","trusted":true},"outputs":[],"source":["data = np.load(\"/kaggle/input/load-scene/lego_200x200.npz\")\n","\n","# Training images: [100, 200, 200, 3]\n","images_train = data[\"images_train\"] / 255.0\n","\n","# Cameras for the training images\n","# (camera-to-world transformation matrix): [100, 4, 4]\n","c2ws_train = data[\"c2ws_train\"]\n","\n","# Validation images:\n","images_val = data[\"images_val\"] / 255.0\n","\n","# Cameras for the validation images: [10, 4, 4]\n","# (camera-to-world transformation matrix): [10, 200, 200, 3]\n","c2ws_val = data[\"c2ws_val\"]\n","\n","# Test cameras for novel-view video rendering:\n","# (camera-to-world transformation matrix): [60, 4, 4]\n","c2ws_test = data[\"c2ws_test\"]\n","\n","# Camera focal length\n","focal = data[\"focal\"]  # float"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:27:53.155502Z","iopub.status.busy":"2023-11-17T00:27:53.155113Z","iopub.status.idle":"2023-11-17T00:27:53.161446Z","shell.execute_reply":"2023-11-17T00:27:53.160464Z","shell.execute_reply.started":"2023-11-17T00:27:53.155474Z"},"id":"VQpqPdlF9OZJ","trusted":true},"outputs":[],"source":["def transform(c2w, x_c):\n","  x_c_homogeneous = np.hstack((x_c, np.ones((x_c.shape[0], 1))))\n","  x_w_homogeneous = np.matmul(c2w, x_c_homogeneous.T).T\n","  x_w = x_w_homogeneous[:, :3] / x_w_homogeneous[:, 3:]\n","  return x_w"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:27:56.035869Z","iopub.status.busy":"2023-11-17T00:27:56.035488Z","iopub.status.idle":"2023-11-17T00:27:56.041302Z","shell.execute_reply":"2023-11-17T00:27:56.040399Z","shell.execute_reply.started":"2023-11-17T00:27:56.035840Z"},"id":"JIGhLQ1e_g0e","trusted":true},"outputs":[],"source":["def pixel_to_camera(K, uv, s):\n","  uv_padded = np.hstack((uv, np.ones((x_c.shape[0], 1))))\n","  K_inv = np.linalg.inv(K)\n","  pixel_c = s * K_inv @ uv_padded.T\n","  return pixel_c.T"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:27:59.094994Z","iopub.status.busy":"2023-11-17T00:27:59.094607Z","iopub.status.idle":"2023-11-17T00:27:59.102940Z","shell.execute_reply":"2023-11-17T00:27:59.101928Z","shell.execute_reply.started":"2023-11-17T00:27:59.094963Z"},"id":"WUOGvR7bGTrs","trusted":true},"outputs":[],"source":["def pixel_to_ray(K, c2w, uv):\n","    w2c = np.linalg.inv(c2w)\n","    ray_o = -1 * np.dot(np.linalg.inv(w2c[:3, :3]), w2c[:3, 3])\n","    uv = np.array(uv)\n","    uv_padded = np.hstack((uv, np.ones((uv.shape[0], 1))))\n","    K_inv = np.linalg.inv(K)\n","    xyz_c = np.dot(K_inv, uv_padded.T).T\n","    xyz_w = transform(c2w, xyz_c)\n","    ray_d = xyz_w - ray_o\n","    ray_d /= np.linalg.norm(ray_d, axis=1, keepdims=True)\n","    length = ray_d.shape[0]\n","    ray_o = np.tile(ray_o, (length, 1))\n","    return ray_o, ray_d"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:29:46.425457Z","iopub.status.busy":"2023-11-17T00:29:46.424723Z","iopub.status.idle":"2023-11-17T00:29:46.434031Z","shell.execute_reply":"2023-11-17T00:29:46.433105Z","shell.execute_reply.started":"2023-11-17T00:29:46.425424Z"},"id":"A9Dc5HOcnHj5","trusted":true},"outputs":[],"source":["def sampleRays(N, images_train, c2ws_train):\n","    Ox = images_train[0].shape[1] / 2\n","    Oy = images_train[0].shape[0] / 2\n","    K = np.array([[focal, 0, Ox], [0, focal, Oy], [0, 0, 1]])\n","    num_images = images_train.shape[0]\n","    num_per_image = N // num_images\n","    image_width = images_train.shape[2]\n","    image_height = images_train.shape[1]\n","    sampled_ray_origins, sampled_ray_directions = [], []\n","    pixel_colors = []\n","    for i in range(num_images):\n","      image = images_train[i]\n","      sampled_x = np.random.randint(image_height, size = num_per_image)\n","      sampled_y = np.random.randint(image_height, size = num_per_image)\n","      sampled_coords = np.column_stack((sampled_x + 0.5, sampled_y + 0.5))\n","      sampled_colors = image[sampled_x,sampled_y ]\n","      pixel_colors.extend(sampled_colors)\n","      ray_o, ray_d = pixel_to_ray(K, c2ws_train[i], sampled_coords)\n","      sampled_ray_origins.extend(ray_o)\n","      sampled_ray_directions.extend(ray_d)\n","    return np.array(sampled_ray_origins), np.array(sampled_ray_directions), np.array(pixel_colors)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:28:06.677369Z","iopub.status.busy":"2023-11-17T00:28:06.676994Z","iopub.status.idle":"2023-11-17T00:28:06.683976Z","shell.execute_reply":"2023-11-17T00:28:06.682818Z","shell.execute_reply.started":"2023-11-17T00:28:06.677337Z"},"id":"vjik58I3Pmk8","trusted":true},"outputs":[],"source":["def sample_along_rays(rays_o, rays_d, perturb=True):\n","    n_samples = 42\n","    near, far = 2.0, 6.0\n","    t = np.linspace(near, far, n_samples)\n","    t_width = 0.5\n","    t = t + (np.random.rand(n_samples) - 0.5) * t_width\n","    ray_os = np.tile(rays_o, (n_samples, 1))\n","    ray_dirs = np.tile(rays_d, (n_samples, 1))\n","    points = ray_os + ray_dirs * t[:, np.newaxis]\n","    return ray_os"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:28:08.846449Z","iopub.status.busy":"2023-11-17T00:28:08.845470Z","iopub.status.idle":"2023-11-17T00:28:08.852389Z","shell.execute_reply":"2023-11-17T00:28:08.851311Z","shell.execute_reply.started":"2023-11-17T00:28:08.846406Z"},"id":"bdvvj1dIVXHS","trusted":true},"outputs":[],"source":["def flatten_images(images):\n","  images_tensor = torch.tensor(images)\n","  x_dim, y_dim, z_dim = images_tensor.size(0), images_tensor.size(1), images_tensor.size(2)\n","  images_tensor_flattened = images_tensor.view(x_dim * y_dim * z_dim, -1)\n","  return images_tensor_flattened"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:28:10.586392Z","iopub.status.busy":"2023-11-17T00:28:10.586058Z","iopub.status.idle":"2023-11-17T00:28:10.593091Z","shell.execute_reply":"2023-11-17T00:28:10.592079Z","shell.execute_reply.started":"2023-11-17T00:28:10.586367Z"},"id":"VjY9UKAt5ldI","trusted":true},"outputs":[],"source":["def sample_along_rays(rays_o, rays_d, perturb=True):\n","      points = []\n","      n_samples = 48\n","      near, far = 2.0, 6.0\n","      t = np.linspace(near, far, n_samples)\n","      t_width = 0.5\n","      t = t + (np.random.rand(n_samples) - 0.5) * t_width\n","      for ray_o, ray_d in zip(rays_o, rays_d):\n","        ray_os = np.tile(ray_o, (n_samples, 1))\n","        ray_dirs = np.tile(ray_d, (n_samples, 1))\n","        points.extend(ray_os + ray_dirs * t[:, np.newaxis])\n","      return np.array(points)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:29:38.581397Z","iopub.status.busy":"2023-11-17T00:29:38.581033Z","iopub.status.idle":"2023-11-17T00:29:38.599464Z","shell.execute_reply":"2023-11-17T00:29:38.598554Z","shell.execute_reply.started":"2023-11-17T00:29:38.581365Z"},"id":"fFCrX50vpSMV","trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","class RaysData(Dataset):\n","    def __init__(self, images_train, K, c2ws_train):\n","        self.images = images_train\n","        self.K = K\n","        self.camera_parameters = c2ws_train\n","        self.num_samples_per_ray = 48\n","        self.ray_origins = []\n","        self.ray_directions = []\n","        self.pixel_colors = []\n","        self.uvs = []\n","        height = images_train[0].shape[0]\n","        width = images_train[0].shape[1]\n","        x_coords, y_coords = np.meshgrid(np.arange(height), np.arange(width))\n","        pixel_positions = np.column_stack((x_coords.ravel(), y_coords.ravel()))\n","        self.uvs = np.tile(pixel_positions,images_train.shape[0])\n","        print(\"uv shape\")\n","        print(self.uvs.shape)\n","        pixel_colors = []\n","        K = np.array([[focal, 0, Ox], [0, focal, Oy], [0, 0, 1]])\n","        self.rays_o = []\n","        self.rays_d = []\n","        for i, image in enumerate(images_train):\n","            pixel_colors.extend(image[pixel_positions[:, 1], pixel_positions[:, 0]])\n","#             c2w = c2ws_train[i]\n","#             uv = self.uvs[height*width * (i - 1):height*width * i]\n","            \n","#             ray_o, ray_d = pixel_to_ray(K, c2w, uv) \n","#             ray_os = np.tile(ray_o, height * width)\n","#             ray_ds = np.tile(ray_d, height * width)\n","#             self.rays_o.extend(ray_os)\n","#             self.rays_d.extend(ray_ds)\n","        self.pixels = np.array(pixel_colors)\n","#         self.rays_o, self.rays_d = np.array(self.rays_o), np.array(self.rays_d)\n","\n","    def sample_rays(self, N = 100):\n","        images_train = self.images\n","        c2ws_train = self.camera_parameters\n","        num_images = images_train.shape[0]\n","        num_per_image = N // num_images\n","        image_width = images_train.shape[2]\n","        image_height = images_train.shape[1]\n","        sampled_ray_origins, sampled_ray_directions = [], []\n","        pixel_colors = []\n","        all_coords = []\n","        for i in range(num_images):\n","            image = images_train[i]\n","            sampled_x = np.random.randint(image_height, size = num_per_image)\n","            sampled_y = np.random.randint(image_width, size = num_per_image)\n","            sampled_coords = np.column_stack((sampled_x , sampled_y))\n","            sampled_coords_offset = np.column_stack((sampled_x , sampled_y))\n","            sampled_colors = image[sampled_coords]\n","            pixel_colors.extend(sampled_colors)\n","            ray_o, ray_d = pixel_to_ray(self.K, c2ws_train[i], sampled_coords_offset)\n","            sampled_ray_origins.extend(ray_o)\n","            sampled_ray_directions.extend(ray_d)\n","            all_coords.extend(sampled_coords)\n","        return np.array(sampled_ray_origins), np.array(sampled_ray_directions), np.array(pixel_colors)\n","\n","    def pixel_to_ray(self, K, c2w, uv):\n","        w2c = np.linalg.inv(c2w)\n","        ray_o = -1 * np.dot(np.linalg.inv(w2c[:3, :3]), w2c[:3, 3])\n","        uv = np.array(uv)\n","        uv_padded = np.hstack((uv, np.ones((uv.shape[0], 1))))\n","        K_inv = np.linalg.inv(K)\n","        xyz_c = np.dot(K_inv, uv_padded.T).T\n","        xyz_w = transform(c2w, xyz_c)\n","        ray_d = xyz_w - ray_o\n","        ray_d /= np.linalg.norm(ray_d, axis=1, keepdims=True)\n","        length = ray_d.shape[0]\n","        ray_o = np.tile(ray_o, (length, 1))\n","        return ray_o, ray_d \n","\n","\n","  # def _sample_points_along_all_rays(self):\n","  #     origins, directions, colors = self.sample_rays()\n","  #     for ray_o, ray_d, color in zip(origins, directions, colors):\n","  #         originsAlongRay = self.sample_points_along_ray(ray_o, ray_d)\n","  #         length = len(originsAlongRay)\n","  #         directionsAlongRay = np.tile(ray_d, (length, 1))\n","  #         colorsAlongRay = np.tile(color, (length, 1))\n","  #         self.ray_origins.extend(originsAlongRay)\n","  #         self.ray_directions.extend( directionsAlongRay)\n","  # #         self.pixel_colors.extend(colorsAlongRay)\n","\n","  # def _sample_along_rays_(self, rays_o, rays_d, perturb=True)\n","  #     n_samples = self.num_samples_per_ray\n","  #     near, far = 2.0, 6.0\n","  #     t = np.linspace(near, far, n_samples)\n","  #     t_width = 0.5\n","  #     t = t + (np.random.rand(n_samples) - 0.5) * t_width\n","  #     ray_os = np.tile(rays_o, (n_samples, 1))\n","  #     ray_dirs = np.tile(rays_dir, (n_samples, 1))\n","  #     points = ray_os + ray_dirs * t[:, np.newaxis]\n","  #     return np.array(points)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T00:28:22.971999Z","iopub.status.busy":"2023-11-17T00:28:22.971308Z","iopub.status.idle":"2023-11-17T00:28:46.668641Z","shell.execute_reply":"2023-11-17T00:28:46.667608Z","shell.execute_reply.started":"2023-11-17T00:28:22.971967Z"},"id":"3my8-2JJ3zz9","outputId":"6f0299f6-5a44-4a01-fb53-4fa746cc20de","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting viser\n","  Obtaining dependency information for viser from https://files.pythonhosted.org/packages/3c/1a/de6f7537c10e3c944f9e53a31b1a6551004fe0a0cc90243e3d805a768bec/viser-0.1.10-py3-none-any.whl.metadata\n","  Downloading viser-0.1.10-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from viser) (12.0)\n","Requirement already satisfied: numpy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from viser) (1.24.3)\n","Requirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from viser) (1.0.5)\n","Requirement already satisfied: imageio>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from viser) (2.31.1)\n","Collecting pyliblzfse>=0.4.1 (from viser)\n","  Downloading pyliblzfse-0.4.1.tar.gz (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: scikit-image>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from viser) (0.21.0)\n","Requirement already satisfied: scipy>=1.7.3 in /opt/conda/lib/python3.10/site-packages (from viser) (1.11.3)\n","Requirement already satisfied: tqdm>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from viser) (4.66.1)\n","Collecting tyro>=0.2.0 (from viser)\n","  Obtaining dependency information for tyro>=0.2.0 from https://files.pythonhosted.org/packages/19/c3/35e23412b4c9b38841ec79f7a69fc57967c8545057ac2ce31647e918b3a2/tyro-0.5.14-py3-none-any.whl.metadata\n","  Downloading tyro-0.5.14-py3-none-any.whl.metadata (7.5 kB)\n","Collecting gdown>=4.6.6 (from viser)\n","  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: rich>=13.3.3 in /opt/conda/lib/python3.10/site-packages (from viser) (13.5.2)\n","Collecting trimesh>=3.21.7 (from viser)\n","  Obtaining dependency information for trimesh>=3.21.7 from https://files.pythonhosted.org/packages/16/65/b458c7118e87681ce3571f76cb0f6663a3642fe6e49502927a56b75328ae/trimesh-4.0.4-py3-none-any.whl.metadata\n","  Downloading trimesh-4.0.4-py3-none-any.whl.metadata (18 kB)\n","Collecting nodeenv>=1.8.0 (from viser)\n","  Obtaining dependency information for nodeenv>=1.8.0 from https://files.pythonhosted.org/packages/1a/e6/6d2ead760a9ddb35e65740fd5a57e46aadd7b0c49861ab24f94812797a1c/nodeenv-1.8.0-py2.py3-none-any.whl.metadata\n","  Downloading nodeenv-1.8.0-py2.py3-none-any.whl.metadata (21 kB)\n","Collecting psutil>=5.9.5 (from viser)\n","  Obtaining dependency information for psutil>=5.9.5 from https://files.pythonhosted.org/packages/19/06/4e3fa3c1b79271e933c5ddbad3a48aa2c3d5f592a0fb7c037f3e0f619f4d/psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Collecting yourdfpy>=0.0.53 (from viser)\n","  Downloading yourdfpy-0.0.53-py3-none-any.whl (22 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown>=4.6.6->viser) (3.12.2)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown>=4.6.6->viser) (2.31.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown>=4.6.6->viser) (1.16.0)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.6.6->viser) (4.12.2)\n","Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio>=2.0.0->viser) (10.1.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nodeenv>=1.8.0->viser) (68.1.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.3.3->viser) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.3.3->viser) (2.16.1)\n","Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.0->viser) (3.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.0->viser) (2023.8.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.0->viser) (1.4.1)\n","Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.0->viser) (21.3)\n","Requirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.0->viser) (0.3)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.2.0->viser) (0.15)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.2.0->viser) (4.5.0)\n","Collecting shtab>=1.5.6 (from tyro>=0.2.0->viser)\n","  Obtaining dependency information for shtab>=1.5.6 from https://files.pythonhosted.org/packages/86/69/3a4873b36d65a1b8f4ee606f5a785b5babb9960385802de60d8455e2f8b6/shtab-1.6.4-py3-none-any.whl.metadata\n","  Downloading shtab-1.6.4-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from yourdfpy>=0.0.53->viser) (4.9.3)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.3->viser) (0.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.18.0->viser) (3.0.9)\n","Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from trimesh>=3.21.7->viser) (6.7.0)\n","Collecting mapbox-earcut (from trimesh>=3.21.7->viser)\n","  Downloading mapbox_earcut-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet (from trimesh>=3.21.7->viser)\n","  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n","  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from trimesh>=3.21.7->viser) (4.19.0)\n","Collecting svg.path (from trimesh>=3.21.7->viser)\n","  Downloading svg.path-6.3-py2.py3-none-any.whl (16 kB)\n","Collecting pycollada (from trimesh>=3.21.7->viser)\n","  Downloading pycollada-0.7.2.tar.gz (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from trimesh>=3.21.7->viser) (1.8.5.post1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from trimesh>=3.21.7->viser) (3.4.1)\n","Requirement already satisfied: rtree in /opt/conda/lib/python3.10/site-packages (from trimesh>=3.21.7->viser) (1.1.0)\n","Collecting embreex (from trimesh>=3.21.7->viser)\n","  Obtaining dependency information for embreex from https://files.pythonhosted.org/packages/0b/dd/18bd405e3c6fc3fc4de25b300f3894d53b2ba1c61c29347fa4032803b9c7/embreex-2.17.7.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n","  Downloading embreex-2.17.7.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.6.6->viser) (2.3.2.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.6.6->viser) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.6.6->viser) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.6.6->viser) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.6.6->viser) (2023.7.22)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.6.6->viser) (1.7.1)\n","Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->trimesh>=3.21.7->viser) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->trimesh>=3.21.7->viser) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->trimesh>=3.21.7->viser) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->trimesh>=3.21.7->viser) (0.9.2)\n","Requirement already satisfied: python-dateutil>=2.2 in /opt/conda/lib/python3.10/site-packages (from pycollada->trimesh>=3.21.7->viser) (2.8.2)\n","Downloading viser-0.1.10-py3-none-any.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n","Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.6/283.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trimesh-4.0.4-py3-none-any.whl (688 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m688.2/688.2 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.5.14-py3-none-any.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.6.4-py3-none-any.whl (13 kB)\n","Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading embreex-2.17.7.post3-cp310-cp310-manylinux_2_28_x86_64.whl (17.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyliblzfse, pycollada\n","  Building wheel for pyliblzfse (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyliblzfse: filename=pyliblzfse-0.4.1-cp310-cp310-linux_x86_64.whl size=22597 sha256=d50960d22b731e7292e0518925ffc73575b307685dcff99200746944d4fed517\n","  Stored in directory: /root/.cache/pip/wheels/d7/a5/02/524ce466ad3c940403767bfe54e967d4070fc88cf6d56ce323\n","  Building wheel for pycollada (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pycollada: filename=pycollada-0.7.2-py3-none-any.whl size=127016 sha256=df860c8bfb212d8151be162560da69048bd1813c515004bbc8f5f6dc2807d10d\n","  Stored in directory: /root/.cache/pip/wheels/d5/ba/33/1e99a7e7defd1d77f0210e7a39ff58de2a2d8d4c22466bb2da\n","Successfully built pyliblzfse pycollada\n","Installing collected packages: pyliblzfse, trimesh, svg.path, shtab, psutil, nodeenv, mapbox-earcut, embreex, chardet, pycollada, tyro, gdown, yourdfpy, viser\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.9.3\n","    Uninstalling psutil-5.9.3:\n","      Successfully uninstalled psutil-5.9.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","beatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.9.1 which is incompatible.\n","beatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\n","jupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.10.1 which is incompatible.\n","raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-5.2.0 embreex-2.17.7.post3 gdown-4.7.1 mapbox-earcut-1.0.1 nodeenv-1.8.0 psutil-5.9.5 pycollada-0.7.2 pyliblzfse-0.4.1 shtab-1.6.4 svg.path-6.3 trimesh-4.0.4 tyro-0.5.14 viser-0.1.10 yourdfpy-0.0.53\n"]}],"source":["!pip install viser"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import viser, time  # pip install viser\n","import numpy as np\n","\n","dataset = RaysData(images_train, K, c2ws_train)\n","rays_o, rays_d, pixels = dataset.sample_rays(100)\n","points = sample_along_rays(rays_o, rays_d, perturb=True)\n","H, W = images_train.shape[1:3] \n","\n","server = viser.ViserServer(share=True)\n","for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n","    server.add_camera_frustum(\n","        f\"/cameras/{i}\",\n","        fov=2 * np.arctan2(H / 2, K[0, 0]),\n","        aspect=W / H,\n","        scale=0.15,\n","        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n","        position=c2w[:3, 3],\n","        image=image\n","    )\n","for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n","    server.add_spline_catmull_rom(\n","        f\"/rays/{i}\", positions=np.stack((o, o + d * 6.0)),\n","    )\n","server.add_point_cloud(\n","    f\"/samples\",\n","    colors=np.zeros_like(points).reshape(-1, 3),\n","    points=points.reshape(-1, 3),\n","    point_size=0.02,\n",")\n","time.sleep(1000) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T00:44:15.935112Z","iopub.status.busy":"2023-11-16T00:44:15.934649Z","iopub.status.idle":"2023-11-16T00:44:16.217749Z","shell.execute_reply":"2023-11-16T00:44:16.216067Z","shell.execute_reply.started":"2023-11-16T00:44:15.935070Z"},"id":"bECrkURIQVq2","trusted":true},"outputs":[],"source":["# Visualize Cameras, Rays and Samples\n","import viser, time\n","import numpy as np\n","\n","dataset = RaysData(images_train, K, c2ws_train)\n","uvs_start = 0\n","uvs_end = 40_000\n","sample_uvs = dataset.uvs[uvs_start:uvs_end]\n","images_train[0, sample_uvs[:,1], sample_uvs[:,0]]\n","assert np.all(images_train[0, sample_uvs[:,1], sample_uvs[:,0]] == dataset.pixels[uvs_start:uvs_end])\n","\n","# Uncoment this to display random rays from the first image\n","indices = np.random.randint(low=0, high=40_000, size=100)\n","\n","# # Uncomment this to display random rays from the top left corner of the image\n","# indices_x = np.random.randint(low=100, high=200, size=100)\n","# indices_y = np.random.randint(low=0, high=100, size=100)\n","# indices = indices_x + (indices_y * 200)\n","\n","data = {\"rays_o\": dataset.rays_o[indices], \"rays_d\": dataset.rays_d[indices]}\n","points = sample_along_rays(data[\"rays_o\"], data[\"rays_d\"], random=True)\n","\n","server = viser.ViserServer(share=True)\n","for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n","  server.add_camera_frustum(\n","    f\"/cameras/{i}\",\n","    fov=2 * np.arctan2(H / 2, K[0, 0]),\n","    aspect=W / H,\n","    scale=0.15,\n","    wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n","    position=c2w[:3, 3],\n","    image=image\n","  )\n","for i, (o, d) in enumerate(zip(data[\"rays_o\"], data[\"rays_d\"])):\n","  positions = np.stack((o, o + d * 6.0)) \n","  server.add_spline_catmull_rom(\n","      f\"/rays/{i}\", positions=positions,\n","  )\n","server.add_point_cloud(\n","    f\"/samples\",\n","    colors=np.zeros_like(points).reshape(-1, 3),\n","    points=points.reshape(-1, 3),\n","    point_size=0.03,\n",")\n","time.sleep(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T01:12:28.668804Z","iopub.status.busy":"2023-11-16T01:12:28.668364Z","iopub.status.idle":"2023-11-16T01:12:28.677222Z","shell.execute_reply":"2023-11-16T01:12:28.675773Z","shell.execute_reply.started":"2023-11-16T01:12:28.668771Z"},"id":"Qcz6PJOsPmk9","trusted":true},"outputs":[],"source":["def volume_render(sigmas, colors, delta):\n","    zero_padding = torch.zeros(sigmas.shape[0], 1, sigmas.shape[2])\n","    sigmas_padded = torch.cat((zero_padding, sigmas), dim=1)\n","    sigmas_padded = sigmas_padded[:, :-1]\n","    T = torch.exp(-torch.cumsum(sigmas_padded * delta, dim=1))\n","    C = T * (1.0 - torch.exp(-sigmas * delta)) * colors\n","    return torch.sum(C, dim=1)"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-11-17T01:11:53.701157Z","iopub.status.busy":"2023-11-17T01:11:53.700117Z","iopub.status.idle":"2023-11-17T01:11:53.714878Z","shell.execute_reply":"2023-11-17T01:11:53.714024Z","shell.execute_reply.started":"2023-11-17T01:11:53.701122Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","class RaysData(Dataset):\n","  def __init__(self, images_train, K, c2ws_train):\n","      self.images = images_train\n","      self.K = torch.tensor(K,dtype=torch.float32)\n","      self.camera_parameters = c2ws_train\n","      self.num_samples_per_ray = 48\n","      self.ray_origins = []\n","      self.ray_directions = []\n","      self.pixel_colors = []\n","      self.uvs = []\n","      height = images_train[0].shape[0]\n","      width = images_train[0].shape[1]\n","      x_coords, y_coords = np.meshgrid(np.arange(height), np.arange(width))\n","      pixel_positions = np.column_stack((x_coords.ravel(), y_coords.ravel()))\n","      self.uvs = np.tile(pixel_positions,images_train.shape[0])\n","      pixel_colors = []\n","      for image in images_train:\n","        pixel_colors.extend(image[pixel_positions[:, 1], pixel_positions[:, 0]])\n","      self.pixels = np.array(pixel_colors)\n","      sample_result = self.sample_rays(images_train.shape[0] * height * width)\n","      self.rays_o, self.rays_d = sample_result[0], sample_result[1]\n","\n","  def sample_rays(self, N = 100):\n","      images_train = self.images\n","      c2ws_train = self.camera_parameters\n","      num_images = images_train.shape[0]\n","      num_per_image = N // num_images\n","      image_width = images_train.shape[2]\n","      image_height = images_train.shape[1]\n","      sampled_ray_origins, sampled_ray_directions = [], []\n","      pixel_colors = []\n","      all_coords = []\n","      for i in range(num_images):\n","          image = images_train[i]\n","          sampled_x = np.random.randint(image_height, size = num_per_image)\n","          sampled_y = np.random.randint(image_width, size = num_per_image)\n","          sampled_coords = np.column_stack((sampled_x , sampled_y))\n","          sampled_coords_offset = np.column_stack((sampled_x , sampled_y))\n","          sampled_colors = image[sampled_coords]\n","          pixel_colors.extend(sampled_colors)\n","          ray_o, ray_d = pixel_to_ray(self.K, c2ws_train[i], sampled_coords_offset)\n","          sampled_ray_origins.extend(ray_o)\n","          sampled_ray_directions.extend(ray_d)\n","          all_coords.extend(sampled_coords)\n","      return np.array(sampled_ray_origins), np.array(sampled_ray_directions), np.array(pixel_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = RaysData(images_train, K, c2ws_train)\n","model = Nerf3D().cuda().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n","loss_fn = nn.MSELoss()\n","for epoch in range(1000):\n","    optimizer.zero_grad()\n","    rays_o, rays_d, rays_rgb = dataset.sample_rays(max_idx = 100, ray_per_image=32)\n","    points = sample_points_from_rays(rays_o, rays_d, near=2.0, far=6.0, num_samples_per_ray=32, train=True)\n","    pred_sigmas, pred_rgbs = model(points.to(device), rays_o.to(device), rays_d.to(device))\n","    rend_img = volrend(pred_sigmas, pred_rgbs, 0.1)\n","    loss = loss_fn(rend_img.to(device), rays_rgb.to(device))\n","    loss.backward() \n","    optimizer.step() \n","    print(f\"Epoch {epoch + 1} Loss: {loss.item():.4f}\") "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()\n","    rays_o, rays_d, rays_rgb = dataset.sample_rays(max_idx = 100, ray_per_image=32)\n","    points = sample_points_from_rays(rays_o, rays_d, near=2.0, far=6.0, num_samples_per_ray=32, train=True)\n","    pred_sigmas, pred_rgbs = model(points.to(device), rays_o.to(device), rays_d.to(device))\n","    rend_img = volrend(pred_sigmas, pred_rgbs, 0.5)\n","plt.imshow(rend_img.detach().cpu().numpy()) "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4007580,"sourceId":6974538,"sourceType":"datasetVersion"},{"datasetId":4009307,"sourceId":6977154,"sourceType":"datasetVersion"}],"dockerImageVersionId":30579,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
